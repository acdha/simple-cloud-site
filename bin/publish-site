#!/usr/bin/env python
# encoding: utf-8
from __future__ import absolute_import, print_function, unicode_literals

from configparser import RawConfigParser
from hashlib import md5
from queue import Queue
from threading import Thread
import os
import sys

from libcloud.storage.types import Provider, ContainerDoesNotExistError
from libcloud.storage.providers import get_driver

from simple_cloud_site.files import find_files

CLOUDFILES = get_driver(Provider.CLOUDFILES_US)


def get_driver_instance(config, container_name):
    """Wrapper to safely get a driver

    This allows us to use the non-thread-safe libcloud within a thread pool
    """

    driver = CLOUDFILES(config.get("auth", "username"),
                        config.get("auth", "api-key"),
                        ex_force_service_region=config.get("auth", "region"))

    try:
        container = driver.get_container(container_name=container_name)
    except ContainerDoesNotExistError:
        container = driver.create_container(container_name=container_name)
        print("Created container %s. You may wish to configure it" % container_name, file=sys.stderr)

    return driver, container


def upload_worker(i, q, config, container_name):
    driver, container = get_driver_instance(config, container_name)

    while True:
        kwargs = q.get()
        print("Uploading %(object_name)s" % kwargs)
        driver.upload_object(container=container, **kwargs)
        q.task_done()


def main():
    config = RawConfigParser()
    config.read([".simple-cloud-site.cfg"])
    # TODO: enforce mode 600!

    source_dir = os.path.realpath(os.curdir)

    # TODO: allow provider configuration
    container_name = config.get("site", "container")

    print("Publishing %s to %s" % (source_dir, container_name))

    driver, container = get_driver_instance(config, container_name)

    upload_queue = Queue()

    workers = [Thread(target=upload_worker, args=(i, upload_queue, config, container_name))
               for i in range(8)]

    remote_objects = {i.name: i.hash for i in container.list_objects()}

    for f in find_files(source_dir):
        target_path = f.replace(source_dir, '').lstrip("/")

        if target_path in remote_objects:
            # TODO: don't read the file twice:
            with open(f, "rb") as local_file:
                h = md5()
                for chunk in iter(lambda: local_file.read(8192), b''):
                    h.update(chunk)
                if h.hexdigest() == remote_objects[target_path]:
                    continue

        upload_queue.put({'object_name': target_path, 'file_path': f})

    print("Waiting for %d uploads to complete…" % upload_queue.qsize())

    for worker in workers:
        worker.setDaemon(True)
        worker.start()

    upload_queue.join()

    print("Configuring static site…")
    driver.ex_enable_static_website(container=container, index_file='index.html')
    driver.ex_set_error_page(container=container, file_name='error.html')
    driver.enable_container_cdn(container=container)
    print("Done")

    print('CDN URL:', driver.get_container_cdn_url(container=container))

if __name__ == "__main__":
    main()
