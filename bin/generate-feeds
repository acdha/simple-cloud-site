#!/usr/bin/env python
# encoding: utf-8
from __future__ import absolute_import, print_function, unicode_literals

from collections import deque
from email.utils import format_datetime
from urllib.parse import urljoin
from warnings import warn

from lxml import etree, objectify

from simple_cloud_site.files import find_html_files
from simple_cloud_site.html import Page
from simple_cloud_site.site import load_site


class Feed(object):
    def __init__(self, metadata):
        self.pages = deque()
        self.metadata = metadata

    def add_page(self, url, page):
        # Ensure that the values are always sortable numbers:
        if not page.last_modified:
            last_modified = 0
        else:
            last_modified = page.last_modified.timestamp()

        self.pages.append((last_modified, url, page))

    def serialize(self):
        raise NotImplementedError


class Sitemap(Feed):
    def serialize(self):
        E = objectify.ElementMaker(annotate=False,
                                   namespace='http://www.sitemaps.org/schemas/sitemap/0.9',
                                   nsmap={None: 'http://www.sitemaps.org/schemas/sitemap/0.9'})

        urlset = E.urlset()

        for last_mod, url, page in self.pages:
            url_elem = E.url(E.loc(url))
            if last_mod:
                url_elem.append(E.lastmod(page.last_modified.isoformat()))
            urlset.append(url_elem)

        return etree.tostring(urlset, pretty_print=True, encoding='utf-8')


class RSS(Feed):
    def add_page(self, url, page):
        if not page.title:
            warn("Skipping %s: missing title" % url)
            return

        if not page.last_modified:
            warn("%s: missing last modified timestamp" % url)

        super().add_page(url, page)

    def serialize(self):
        E = objectify.ElementMaker(annotate=False, nsmap={"atom": "http://www.w3.org/2005/Atom"})

        channel = E.channel(E.title(self.metadata['site_title']),
                            E.link(self.metadata['site_url']),
                            E.description(self.metadata['site_description']))

        channel.append(etree.Element("{http://www.w3.org/2005/Atom}link", rel="self",
                                     href=urljoin(self.metadata['site_url'], "/feeds/all.atom")))

        for last_mod, url, page in sorted(self.pages, key=lambda i: i[0], reverse=True)[:10]:
            item = E.item(E.title(page.title), E.link(url),
                          E.guid(url, isPermaLink="true"))

            if page.description:
                item.append(E.description(page.description))

            if page.last_modified:
                item.append(E.pubDate(format_datetime(page.last_modified)))

            channel.append(item)

        rss = E.rss(channel, version="2.0")

        return etree.tostring(rss, pretty_print=True, encoding='utf-8', xml_declaration=True)


class Atom(RSS):
    def serialize(self):
        E = objectify.ElementMaker(annotate=False, nsmap={None: "http://www.w3.org/2005/Atom"})

        feed = E.feed(E.title(self.metadata['site_title']),
                      E.id(self.metadata['site_url']),
                      E.link(rel="self", href=urljoin(self.metadata['site_url'], "/feeds/all.atom")),
                      E.subtitle(self.metadata['site_description']),
                      E.author(E.name(self.metadata['author_name']),
                               E.email(self.metadata['author_email'])))

        pages = sorted(self.pages, key=lambda i: i[0], reverse=True)

        feed.append(E.updated(pages[0][2].last_modified.isoformat()))

        for last_mod, url, page in sorted(self.pages, key=lambda i: i[0], reverse=True)[:10]:
            entry = E.entry(E.title(page.title), E.id(url), E.link(href=url))

            if page.description:
                entry.append(E.summary(page.description))

            if page.articleBody:
                entry.append(E.content(page.articleBody, type="html"))

            if page.last_modified:
                entry.append(E.updated(page.last_modified.isoformat()))

            feed.append(entry)

        return etree.tostring(feed, pretty_print=True, encoding='utf-8', xml_declaration=True)


def main():
    site = load_site()

    site_info = {
        'site_url': site.base_url,
        'site_title': site.config.get('site', 'site_title'),
        'site_description': site.config.get('site', 'site_description'),
        'author_name': site.config.get('author', 'name'),
        'author_email': site.config.get('author', 'email'),
    }

    sitemap = Sitemap(site_info)
    rss = RSS(site_info)
    atom = Atom(site_info)

    for f in find_html_files(site.base_dir):
        path = site.filename_to_url(f)

        if path == '/':
            continue  # Skip the index page

        url = urljoin(site.base_url, path)

        p = Page(f)

        sitemap.add_page(url, p)
        if p.is_blog_post:
            rss.add_page(url, p)
            atom.add_page(url, p)

    with open('sitemap.xml', 'wb') as f:
        f.write(sitemap.serialize())

    with open('feeds/all.rss', 'wb') as f:
        f.write(rss.serialize())

    with open('feeds/all.atom', 'wb') as f:
        f.write(atom.serialize())


if __name__ == "__main__":
    main()
